### Utils (logging, train file, etc)
util_config:
  model_name: 
  save_path: 
  log_path: 
  min_delta_early_stop: 0.025 # loss are weighted to be ~1 
  patience_early_stop: 15
  steps_per_epoch: 2500
  validation_steps: 500
  plateau_lr_factor: 0.33
  plateau_lr_patience: 5
  min_delta_early_stop_sigma: 0.01 # loss are weighted to be ~1 
  patience_early_stop_sigma: 15
  steps_per_epoch_sigma: 2500
  validation_steps_sigma: 500
  plateau_lr_factor_sigma: 0.33
  plateau_lr_patience_sigma: 5

### NN arch
nn_arch_config:
  # activation function
  nn_act_function: selu # leaky_relu, gelu, selu, ...
  # dt sequence analyzer
  dt_sequence_analyzer:
    lstm_units: 36
    regul: 0.
    lstm_state_creator_size: 24
    dim_det_enc: 10
  # dt grid bundle
  dt_geom_grid:
    spatil_1_conv: {filters: 32, kernel_size: [3, 3], strides: [1, 1], padding: same}
    spatil_2_conv: {filters: 46, kernel_size: [3, 3], strides: [1, 1], padding: same}
    spatil_3_conv: {filters: 46, kernel_size: [2, 2], strides: [1, 1], padding: same}
    spatil_4_conv: {filters: 46, kernel_size: [2, 2], strides: [1, 1], padding: valid}
    spatil_pool: {pool_size: [2, 2], padding: valid}
    dim_grid_encs: 10
    regul: 0.
    dr_rate: 0.0
  # parameter prediction
  preds_branch_params: 
    units: [32, 32, 24, 24, 16]
    drops: [0., 0., 0., 0., 0.]
    regularization: 0.0
  # uncertainty estimation 
  sigmas_branch_params: 
    units: [24, 16, 8]
    drops: [0.0, 0.0, 0.0]
    regularization: 0.0
  # waveforms encoder
  wf_encoder_params: 
    dr_rate: 0.0
    regul: 0.0
    dim_wf_encs: 12
    first_2d_conv: {filters: 32, kernel_size: [6, 1], strides: [1, 1], padding: same}
    second_2d_conv: {filters: 46, kernel_size: [6, 2], strides: [1, 1], padding: valid}
    last_1d_conv: {filters: 46, kernel_size: 6, strides: 2}
    # rnn subnetwork
    wf_rrn_params:
      first_lstm_size: 36
      second_lstm_size: 46
      regul: 0.0
      lstm_state_creator_size: 32

### NN compilation
nn_compile_config:
  # optimizers
  optimizers: 
    optimizer_preds: 
      name: Adam
      kwargs: {learning_rate: 0.002, beta_1: 0.9, beta_2: 0.999, epsilon: 1.e-07, amsgrad: false}
    optimizer_sigma: 
      name: Adam
      kwargs: {learning_rate: 0.001, beta_1: 0.9, beta_2: 0.999, epsilon: 1.e-07, amsgrad: false}
  # weights for losses and particles
  weights_training_parameters:
    weights_loss_preds: [1.0, 0.15, 1.0] # lnA, lnE, dir; ~ 1, 0.15, 1
    weights_loss_sigma: [1.0, 1.0, 1.0] # lnA, lnE, dir; should be approx equal for rescaled sigma
    weights_loss_calls: [2.5e+0, 6.0e+1, 3.3e+3] # ~ 2.5e+0, 6.0e+1, 3.3e+3; used for callbacks, set each loss ~ 1
  # sigma rescaling 
  means_preds: [4.3e-1, 1.2e-2, 1.0e-4] # lnA, lnE, dir; ~ 4.3e-1, 1.2e-2, 8.0e-5
 
### dataset creation
dataset_params:
  h5f_train: 
  batch_size : 256
  weights_particles: [1.0, 1.0] # pr, fe 
  # labels normalization
  norm_E_params : [1.805951, 0.4291] # mean, std
  ## noise parameters
  # addative gauss
  apply_gauss: {dt_params: false, wfs_flat: false, recos: false, dt_bundle: false}
  gauss_stds:
    dt_params: [0.05, 0.05, 0.0, 0.1, 0.005, 0.02]
    wfs_flat: [0.01, 0.01]
    recos: [0.3, 0.3, 0.5, 0.1, 0.0, 0.0, 0.03, 5.0, 5.0, 0.05, 0.05, 3.0, 0.01, 2.0, 1.0]
    dt_bundle: [0.05, 0.05, 0.0, 0.1, 0.005, 0.02, 0.0]
  # multiplicative gauss
  apply_mult_gauss: {dt_params: false, wfs_flat: false, recos: false, dt_bundle: false}
  gauss_mult_stds: {dt_params: [0.1], wfs_flat: [0.1], recos: [0.1], dt_bundle: [0.1]}
  # Generator parameters
  dense_def_vals_dts: [4.0, 4.0, 0.0, 4.0, 4.0, 0.0, 0.0]
  dense_def_vals_wfs: [[-4.0, -4.0]]
  return_reminder: false
  prefetch_method : auto # auto or int number
